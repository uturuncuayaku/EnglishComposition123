




7-4 Assignment: Persuasive Essay 
Andres
Southern New Hampshire University
English Composition II
Professor Erin Stettner, M.A.
Monday, June 19, 2022
 

Decision making worldwide is a job being done by Artificial Intelligence which is imperative to our future growth as a major player in the worldwide competitive markets by predicting consumer trends in business or by assisting the government to pass judgment on criminals and allocate funds equitably. The “black box” of information called AI is a computer machine process that uses big data to generate predictive results or to figure out complex solutions for humans and is the perfect tool to automate certain tasks based upon directed criteria or parameters such as filling out forms or auditing forms for compliance. Perfect for businesses and government to make transactions smooth and flawless through the assistance of repetitive tasks or clerical duties that generate loss of productivity in human capital, i.e., time. (2015, Marr) But algorithms in the USA should require a driving license to go along with the unbiased decisions that govern a Tesla's autopilot which is able to detect pedestrians and avoid accidents on the road. Current use of the decisions and results within these “black boxes” should be halted if they are public facing because creating a negative impact to social groups and the risk of loss of employment from diverse cultures, races, or identities hurt our economy. The forward progression of society is to live peacefully and justly through anti-discriminatory laws and without bias that infiltrates human good from extremists. Businesses and government on the other hand are not fulfilling their part of contributing to society because algorithms have been known to promote racialized porn on Google to researchers, re-incarcerate black prisoners over white prisoners at a much higher rate, or develop algorithms that are inadequately studied for continual public use which influences social inequality leading to a lower participation of minorities in the workforce through stigma or low self-esteem for a lack of diverse role models in mainstream employment due to algorithms deciding what a user sees when performing a search on its database of the cyberspace, or for promoting opinions about professional work appearance that only influences white people positively and puts minorities down as unprofessional for being different. This algorithmic bias can be eliminated by a moderating agency giving license of use during fulfillment because algorithms generate inequitable decisions affecting the community, analyzing machine learning algorithms will highlight ways researchers are inadequately prepared, and these algorithms produce ineffective results for researchers. 
The promise of this technology demands oversight for our world because stopping the algorithmic biases inherent in computers leads to stronger and thriving communities otherwise it will cost minorities their jobs and freedom granted by the Constitution. (O’Brien, 2020) Our government is using AI by analyzing inmates for recidivism rates to set bail amounts in court hearings. The way these algorithms contribute to the negative lifecycle of communities is that introducing unfair biases from collected data such as skin color or malicious data acquisition causes the algorithm to produce inequitable results, allowing white inmates lower bail amounts therefore less time in jail promoting black inmates to longer jail sentences so that they are more likely to go back to jail after time served. Resulting in biased decision-making systems that compound the effects of discrimination of one race versus the other. (O’Brien, 2020) This detrimental cascading effect over time would be avoidable if a neutral third party was able to verify the results and licensure of an algorithms effectiveness and neutrality of moral and applicable laws throughout the lifecycle of use and application. But local economies deserve the moral obligation to participate in the larger economy respectfully without shame for our nation but for this to happen the communities affected by this A.I should expect to be treated fairly to prevent negative economic lifecycles of minority races which in the past has led to discrimination laws propping up social order but still ultimately causing “indirect effects of the criminal legal system.” (Decker, 2021) Morality leads to a just and equitable future for everyone through the study and applicable uses of law where citizens are willing to participate in the economy with their protected rights governed by our elected congressman and woman. Minorities being incarcerated and held at higher bail amounts than their white counterparts equates to money being lost from jobs, and the communities they live in bear the brunt of lifetime earnings lost which is twice of that of the white counterparts sometimes as much as “$511,500.”(Craigie, et al., 2020) Illustrating this simple use case of a complex algorithmic model helping lawmakers pass judgement culminates toward “disparate impacts” in the community because it leads to “lost contact with family, employment and other sources of social stability.”(O’Brien, 2020) These patterns of our judicial system highlight the work needed to move our nation forward towards licensure of algorithmic competency and to help spread social awareness to these difficult issues that complicate machine learning models and data.
Researchers having culturally unaware data scientists responsible for aggregating big data and providing solutions from the results of these machine learning algorithms are graduating without the social sensitivity and knowledge needed to generate successful consequential AI results. A standard that is being implemented by the scientific community to combat this is to insert Fairness, Accountability, Transparency and Ethical (FATE) attributes during the evolution of all AI implementations in social contexts. (ACM, 2021) Researcher’s and professionals attending school or whilst employed should be made aware of the different “performance metrics and technical definitions of diverse social values within a community to negotiate and synthesize the perspectives of diverse stakeholders” (Hong et al., 2021) to produce FATE based machine learning outcomes, thus moving towards the right direction of implementing an oversight into the inner workings and results of public facing consequential algorithms. Also, research has shown that researchers have “an incoherent theory of what social categories are” while they pursue machine learning fairness and social explain-ability concepts during AI research in the social sciences and philosophical arts.(Atoosa, 2021) The social impacts computer science students can have within the community of diverse cultures concretely solidifies the idea that licensure of algorithms should become the normative standard to promote a fair and equitable future for all instead of dystopic Mad Max version’s depicted in the media glorifying the AI as the terminator of humans. The vast quantities of different cultures are affected by algorithmic biases, either purposely coded that way or through a lack of oversight that leads to more biases which shows our inherent, latent biases in mankind at controlling the decision-making outcomes of machinery. Introducing the social need for complex methodologies by removing obstacles to promote culturally insensitive college students within the field of data and computer science into the ranks of the professional information technology workforce. 
Ineffective algorithms have reported back sexualized searches from normal words that infer no sexual connection to the input. Exhibiting the need for agency because promoting a sexualized result where another’s protected class isn’t affected by this result of the same search sequence is unfair and leads to a prejudiced society. Promoting a sexualized context when the counterpart isn’t hyper-sexualized by race during one search but not the other implies a malicious bias in reflection of the demographics by observation of an algorithm that should be hidden away from the end user as this isn’t the case to how people speak or interact in real life. A phrase is used often in an area but determining what reaches the consumer should be equitable and professional. Note the inner workings of an algorithm assuming learned behaviors from social media comments where a person can let their vocabulary imagination flow towards harmful sayings and connotations that have no place in civil society and have no place in the computing industry. Using a service of the information highway to generate results we want amplify these biases but without transparency or licensure it becomes an issue needed to be looked at firmly and consecutively because a search result perpetuating racism isn’t technologically sound. Or the horror of looking for positive messages in a time of crisis but being met with the wrong depiction of the world instigated by a trivial math and statistical problem that colleges supposedly prepare students to undertake and solve during our times of political injustice rallies around the world. Leading people to have an unfavorable view causing implicit biases or in other words biases we are not consciously aware of and creating an algorithm that doesn’t learn the harmful effects of this can create an unjust and unstable future for society. Which again, leads to search results becoming biased and sexualizing one group over another. This cyclic effect has the potential to snowball out of control by generating disparate communities by further entrenching marginalized groups into shame, debt, and longer jail sentences through lack of acknowledgement of current laws and regulations regarding discriminatory practices. Ignorance is not bliss but a licensure of approved results that enforce non-biased applicable parameters to these machine learning algorithms are imperative for consumer use cases. Negative effects by google or social media search results can be mitigated and potentially spur further action if there was an agency in agreement with companies on the expected outcomes and realities associated with these types of algorithms that are public facing and making decisions that impact the community. There will be more people effected positively instead of the negative portrayal these past search results have provided. Algorithmic missteps can generate a negative influence on the stereotypes associated with these searches resulting in people believing and parroting racist viewpoints about the protected classes association to these words that generated the results. 
Opposing licensure of algorithms is natural for businesses to support in the short term so that their long-term profitability in the market becomes essential to the workforce development of our nation. The fear of losing intellectual property is a valid concern to many small and large businesses looking to implement trivial computer systems that are designed to automatically generate money prompting an evolution of higher standards and work-life balance. Bringing in an external entity to oversee the licensing and integrity of an algorithm’s decision-making capabilities exposes businesses to corporate espionage events that generate lost revenue leading to slow growth of business and ultimately to the company’s future. Stopping businesses and government from immediately stopping the use of decision-making algorithms that are ubiquitous and generically positive is wasteful because most systems implementing this tool are trivial and inconsequential. Therefore, leading to an increase of research and development generating lost time to the American public’s workforce. Increasing business costs and delaying progress of a trusted process. Businesses and the economy will see a boost to their bottom-line implementing machine learning techniques to help land people their first jobs, keep crime off the streets and direct public funds towards a need or at-risk communities promoting a positive economic lifecycle. This utopic viewpoint is an oppositional view to requiring a license before use of algorithmic results. This belief states that the economy will grow, and businesses will hire more people to keep up with demand in today’s algorithmic utopia. It is important to understand the risks of having AI licensure and setting up the already burdened government with more agencies and skilled people that are needed in the engineering community which places a burden on the world financially. But this cannot impede the growth and rapid pace of innovation of a talented workforce growing in numbers year after year stifled by the oversight an agency providing licensure requires. 
The tools currently used online to show us recommendations on social media based on our preferences, and in business to drive autonomous behaviors like ordering inventory before a store runs out of a product or to drive the economy forward through employment rely on machine learning algorithms. These decision-making abilities of AI are autonomous and without human interaction until the results are applied, such as the store doesn’t run out of ice cream when the weather is hot or linking us to a food blogger from our home country while browsing TikTok in another. Highlighting the complexities involved which require a need for precise and accurate results. In the long term, having algorithms buy our goods before we run out and promote a positive society will be up to the engineers in charge and that is why licensing could work. During the development of machine learning algorithms and the customer becoming the focus and use case of this technology to help businesses predict outcomes or consumer behavior to guide this adaptive intelligence system. There needs to be oversight and complete acceptance through compliance standards already set in motion by the U.S and Europe through the current privacy and patent laws before an AI machine algorithm is implemented. The contrasting and intertwined capabilities of business and oversight of government of autonomous systems require careful consideration from expert opinion in the data science field. Data acquisition to analyzing resultants of this data to eliminate human biases that push racist agendas burdening the economy indirectly by pushing out minorities and woman from participation. Licensing the results of these machines at businesses, the point of contact for the public to the outside world of their lives. Influences the rest of civil society to generate profit and look at a tool that is consistently evolving and being researched as we progress towards equitable and community enriching endeavors for the sake of being good citizens and world leaders. Playing human games as an Artificial Intelligence machine is the right path for non-licensure. But our human lives moving forward as healthy, proactive socially conscious consumers have been impacted negatively placing us at the cusp of an inequitable future further placing the burdens of America’s difficult past into the limelight. Causing irreparable harm to the business and social environment we must confront every day as we see homelessness, high job employment loss, separated families, and financial burdens placed upon communities across the nation. These effects will be seen not just today but during the rest of our lives unless we can control the algorithms through aggressive dominant oversight of algorithmic policy.  
 
References
Craigie, T.-A., Grawert, A., & Kimble, C. (2020, September 15). Conviction, imprisonment, and lost earnings: How involvement with the criminal justice system deepens inequality. Brennan Center for Justice. Retrieved June 16, 2022, from https://www.brennancenter.org/our-work/research-reports/conviction-imprisonment-and-lost-earnings-how-involvement-criminal
Decker, G. (2021). Occupational Licensing as a Barrier for People with Criminal Records: Proposals to Improve Anti-Discrimination Law to Address Adverse Employment Impacts from the Criminal Legal System. Fordham Urban Law Journal, 49(1), 189–219.
Kasirzadeh, A., & Smart, A. (2021). The Use and Misuse of Counterfactuals in Ethical Machine Learning. https://doi-org.ezproxy.snhu.edu/10.1145/3442188.3445886
O'Brien, T. (2021). Compounding injustice: The cascading effect of algorithmic bias in risk ... Retrieved May 31, 2022, from https://www.law.georgetown.edu/mcrp-journal/wp-content/uploads/sites/22/2021/05/GT-GCRP210003.pdf
Hong Shen, Wesley H. Deng, Aditi Chattopadhyay, Zhiwei Steven Wu, Xu Wang, Haiyi Zhu, 3–10, 2021, Virtual Event, Canada. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3442188.3445971
Marr, B. (2015). Big data : using smart big data, analytics and metrics to make better decisions and improve performance. John Wiley & Sons.
Noble, S. U. (2018). Algorithms of oppression: data discrimination in the age of google. New York University Press.
Statement on algorithmic transparency and Accountability. (n.d.). Retrieved May 4, 2022, from https://www.acm.org/binaries/content/assets/public-policy/2017_usacm_statement_algorithms.pdf
Wagner, C., Strohmaier, M., Olteanu, A. et al. Measuring algorithmically infused societies. Nature 595, 197–204 (2021). https://doi.org/10.1038/s41586-021-03666-1
